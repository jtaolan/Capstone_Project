{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Media Consolidation and Financialization Analysis \n",
    "## <center> From 1995 to 2019, USA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Author: Jiaohaer Taolan \n",
    "<center> M.S. Student in Computational Social Sicnece\n",
    "\n",
    "<center> La JoIIa, Ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Table of contents\n",
    "#### <center>Introduction\n",
    "#### <center>Background and Literature Review\n",
    "#### <center>Methods\n",
    "#### <center>Content Main Body\n",
    " <center> - SQL Project\n",
    " <center> - Tablesu Project\n",
    " <center> - Statistical Modeling Project\n",
    " \n",
    "#### <center>Referenses\n",
    "#### <center>Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence of media financialization and consolidation has become a focal point of academic inquiry as media organizations increasingly navigate a landscape shaped by economic, technological, and regulatory changes. Media financialization refers to the growing influence of financial markets, investors, and financial logic on media companies, while media consolidation involves the merging and integration of media entities, leading to a concentration of ownership and power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Background and Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As media industries have undergone significant transformations in recent decades, researchers have sought to understand the implications of financialization and consolidation on the structure, content, and economic dynamics of the media landscape. Scholars have explored the impact of financialization on media organizations, investigating how financial pressures shape content production, distribution strategies, and journalistic practices. \n",
    "\n",
    "deWaard (2023)delves into the financial capital in the cultural industries, and the relationship between American film, television, popular music industry and the financial firms which is making multiple dimensions of inequality. \n",
    "\n",
    "McChesney (1999) delves into the financialization of media and its implications for journalism, highlighting the tensions between profit motives and the societal role of the media. Baker and McDonald (2018) examine the role of financial markets in shaping media policy, emphasizing the need to understand media as a financial asset class.\n",
    "\n",
    "The consolidation of media ownership has been a prominent area of study, with Bagdikian's seminal work (2004) providing an early exploration of the consequences of media concentration. Compelling empirical studies, such as Cunningham and Sinclair's (2017) analysis of global media ownership patterns, shed light on the extent and implications of consolidation. Researchers like Napoli (2001) have focused on regulatory frameworks, illustrating how policy decisions influence the consolidation process.\n",
    "\n",
    "An emerging strand of research examines the interconnectedness of financialization and consolidation. Picard (2012) explores the relationship between financial strategies and media consolidation, arguing that financial imperatives often drive consolidation efforts. The work of Doyle and McChesney (2020) provides insights into how financialization exacerbates consolidation trends, impacting media diversity and democratic discourse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tData Source\n",
    "\n",
    "The data is from Macro Lab (originally from LSEG Refenitiv, a real-time financial data and news provider). \n",
    "\n",
    "2.\tFramework\n",
    " - Tableau - Data visualization software\n",
    " - SQL - a standard language for accessing and manipulating databases\n",
    "Creating relational database for Macro lab using IBM DB2 and AWS cloud. Querying data from relational database and load it into Tableau would made data importing process safer and ready to use. Although it is ok to connect data source from google drive in Tableau, it is not viable to modifying data. Hoever while using SQL would make it more easier to wrangle and update the data directly. \n",
    "\n",
    " - Python – For data modeling and prediction\n",
    "Using library of NumPy, pandas, matplotlib, sklearn, and pytorch to preprocessing and wrangling data, build supervised machine learning algorithms (such as Linear Regresion, Double Layer Neural Network) to do the data modeling and prediction. \n",
    "\n",
    " - GitHub – for version control\n",
    " \n",
    "\n",
    "3.\tStatistical Modeling Analysis\n",
    "\n",
    " - Linear Regression\n",
    "\n",
    " - Double-Layer Neural Network\n",
    "\n",
    " - Model evaluation and comparison \n",
    "The evaluation of performance of different models should be performed by comparing the predicted scores to the true labels. The MSE(Mean Square Error) and R-squared Score should be called.\n",
    "In the end, the linear regression, Double Layer Neural Network are appropriate for addressing the specific aspects of media financialization and consolidation because they offer a versatile and complementary set of tools that collectively allow for a nuanced analysis of the intricate relationships between key financial indicators and the dynamics of media consolidation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Content Main Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> SQL Database Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Conda environment setup\n",
    "```bash\n",
    "source ~/miniconda3/bin/activate\n",
    "conda create -n myenv python=3.9\n",
    "conda activate myenv\n",
    "```\n",
    "\n",
    "If conda is not installed, install conda (Linux system for example)\n",
    "```bash\n",
    "mkdir -p ~/miniconda3\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: pandas==1.5.3 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: openpyxl in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.0.7)\n",
      "Requirement already satisfied: sqlalchemy in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.4.7)\n",
      "Requirement already satisfied: sqlalchemy-utils in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.41.2)\n",
      "Requirement already satisfied: pymysql in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (0.24.1)\n",
      "Requirement already satisfied: torch in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from openpyxl->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from sqlalchemy->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/jiaohaidediannao/opt/anaconda3/lib/python3.8/site-packages (from torch->-r requirements.txt (line 8)) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "# install the required packages from the requirements.txt file\n",
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read xlsx files and write to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "from pandas.io import sql\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "\n",
    "# Create an engine for MySQL using PyMySQL\n",
    "user = input(\"Enter your MySQL username: \")\n",
    "password = input(\"Enter your MySQL password: \")\n",
    "# engine = create_engine(\"mysql+pymysql://test_user:123!@localhost/test_database\")\n",
    "base_engine = create_engine(f\"mysql+pymysql://{user}:{password}@localhost/\")\n",
    "\n",
    "\n",
    "def my_create_database(base_engine, database_name):\n",
    "    \"\"\" \n",
    "    Create a new database if it does not exist\n",
    "    then return the engine for the new database\n",
    "    \"\"\"\n",
    "    con = base_engine.connect()\n",
    "    cmd = text(f\"CREATE DATABASE IF NOT EXISTS `{database_name}`;\")\n",
    "    try:\n",
    "        con.execute(cmd)\n",
    "    except Exception as err:\n",
    "        pass\n",
    "    con.close()\n",
    "    db = create_engine(f\"mysql+pymysql://{user}:{password}@localhost/{database_name}\")\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "\"\"\" the main function to process the excel files and write them to mysql database \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_dir = \"./demo_datasets/\"\n",
    "    logging_dir = \"./logs/\"\n",
    "    if not os.path.exists(logging_dir):\n",
    "        os.makedirs(logging_dir)\n",
    "\n",
    "    xls_file_list = sorted(glob.glob(os.path.join(dataset_dir, \"**/*.xlsx\"), \n",
    "                                     recursive=True))\n",
    "    # print(xls_file_list)\n",
    "\n",
    "    for xls_file in xls_file_list:\n",
    "        xls_file_name = os.path.basename(xls_file).split(\".\")[0]\n",
    "        # read excel sheets to data frames\n",
    "        try:\n",
    "            xls = pd.ExcelFile(xls_file)\n",
    "            print(\"=============== Processing file: \", xls_file)\n",
    "        except Exception as err:\n",
    "            # log the errors to a file\n",
    "            with open(\"./logs/error_log_file.txt\", \"a\") as f:\n",
    "                f.write(f\"Error reading file: {xls_file}\\n\")\n",
    "                f.write(f\"Error: {err}\\n\")\n",
    "            continue\n",
    "\n",
    "        # create a new database based on the excel file name\n",
    "        db = my_create_database(base_engine, xls_file_name)\n",
    "\n",
    "        # write each sheet to a table in the database\n",
    "        sheet_names = xls.sheet_names\n",
    "        for sheet_name in sheet_names:\n",
    "            # read excel sheet to data frame\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "            \n",
    "            # data frames to sql tables one by one\n",
    "            if not df.empty:\n",
    "                print(\"Processing sheet: \", sheet_name)\n",
    "                try:\n",
    "                    df.to_sql(sheet_name, con=db, if_exists='replace', index=False)\n",
    "                except Exception as err:\n",
    "                    # log the errors to a file\n",
    "                    with open(\"./logs/error_log_sheets.txt\", \"a\") as f:\n",
    "                        f.write(f\"Error in sheet in file: {sheet_name, xls_file}\\n\")\n",
    "                        f.write(f\"Error: {err}\\n\")\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above code, we show that the new databases and tables are created in the mysql database. The results are as following figures. \n",
    "\n",
    "<!-- ![Figure 1](./figs/database_1.png)\n",
    "![Figure 2](./figs/database_2.png) -->\n",
    "\n",
    "<img src=\"./figs/database_1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"./figs/database_2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Database \"10K\" as example, to see the content of it.\n",
    "\n",
    "<!-- ![Figure 3](./figs/database_3.png) -->\n",
    "\n",
    "<img src=\"./figs/database_3.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Tableau Project :Concentration Index Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Herfindahl-Hirschman Index Tableau Dashborad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concentration index analysis covered various media markets including film, music, books&publishing, and video gaming. It includes 12 different datasets gathered from the MACRO Lab folder and the Statista platform. The data comprises both continuous and discrete datasets, providing a comprehensive overview of market dynamics. \n",
    "\n",
    "Continuous datasets, representing market share percentages over time (for example, the market share of leading film studios in the US and Canada from 2010 to 2023) have been imported into Tableau for visualization and analysis. These datasets allow for the examination of trends and patterns in market dominance within specific segments of the media industry. Sheets have been created in Tableau to visualize these datasets, providing insights into the relative positions of key players. \n",
    "\n",
    "Discrete datasets, presenting market share data for specific periods or events(for example, the market share for mobile gaming publishers in 2021 Q2 U.S.) require a different approach for analysis. These datasets have been processed to create separate pie charts, highlighting the distribution of market share among key players in the media industry during distinct timeframes or circumstances. \n",
    "\n",
    "The first step of data analysis was data wrangling and calculating the HHI index for each dataset. The original datasets only have information on the market share of media commercial entities in percentage. So, I calculated the HHI index using its formula which is summing up the squares of the market shares of all firms in the market. Then the processed data was organized together to make visualization on the Tableau desktop.\n",
    "\n",
    "As you can see in the Tableau Story, the first two dashboards are discrete dataset visualization while the last one is a combination of all the linear datasets.\n",
    "\n",
    "It's important to note that different segments of the media industry exhibit varying levels of market concentration, as indicated by the Herfindahl-Hirschman Index (HHI). Some sectors may have an HHI index as high as 6000+, signifying high concentration and dominance by a few major players, while others may have an HHI index below 2500, indicating a more diversified market landscape. Also, note that some data sources don’t include holistic information about all the companies within that industry so it’s impossible to calculate their HHI index and that’s why we only got a limited amount of datasets to run the analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='tableauPlaceholder' id='viz1714869848378' style='position: relative'><noscript><a href='#'><img alt='Concentration Index Analysis for Media Industry ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;P6&#47;P644QNGS8&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='path' value='shared&#47;P644QNGS8' /> <param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;P6&#47;P644QNGS8&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1714869848378');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1714869848378' style='position: relative'><noscript><a href='#'><img alt='Concentration Index Analysis for Media Industry ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;P6&#47;P644QNGS8&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='path' value='shared&#47;P644QNGS8' /> <param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;P6&#47;P644QNGS8&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1714869848378');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='tableauPlaceholder' id='viz1714870034415' style='position: relative'><noscript><a href='#'><img alt='&lt;Key Financials : market cap, revenue, profit&gt; ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Up&#47;Updated_Key_Financials_v2024_4_25&#47;KeyFinancials&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='Updated_Key_Financials_v2024_4_25&#47;KeyFinancials' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Up&#47;Updated_Key_Financials_v2024_4_25&#47;KeyFinancials&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1714870034415');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1714870034415' style='position: relative'><noscript><a href='#'><img alt='&lt;Key Financials : market cap, revenue, profit&gt; ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Up&#47;Updated_Key_Financials_v2024_4_25&#47;KeyFinancials&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='Updated_Key_Financials_v2024_4_25&#47;KeyFinancials' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Up&#47;Updated_Key_Financials_v2024_4_25&#47;KeyFinancials&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1714870034415');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Statistical Modeling Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Data preparation\n",
    "In this problem, We investigate the relationship between \n",
    "\n",
    "- Total inflation adjusted box office ($I$)\n",
    "- Revenue of the film & video production ($R$)\n",
    "- Employment in the motion picture & sound recording industries in the U.S (in 1,000s) ($E$), \n",
    "- Consumer spending on movie tickets in the U.S. 1999-2022($C$), \n",
    "- Box office revenue in the United States($B$), \n",
    "- U.S. consumer spending on Subscription streaming($S$), \n",
    "- Mergers & Acquisitions in the film industry($M$),\n",
    "\n",
    "versus the index HHI. And index HHI is calculated by the formula: \n",
    "$$HHI = \\sum_i(p_i^2)$$\n",
    "where $p_i$ is the market share of the i-th company.\n",
    "\n",
    "### (2) Data preprocessing\n",
    "We normalize the data $X$ to the range of $[0, 1]$ by using the formula:\n",
    "$$X = \\frac{X - X_{min}}{X_{max}- X_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we plot the normalized data to see the trends of the quantities versus time, and also see if there is any correlation between the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(\"regression.xlsx\")\n",
    "df = pd.read_excel(xls)\n",
    "\n",
    "# determine the number of rows and columns\n",
    "n_rows, n_cols = df.shape\n",
    "\n",
    "for col in df.columns[1:]:\n",
    "    # split the name with space\n",
    "    # new_col = col.split(\" \")[0] + \"_\" + col.split(\" \")[1]\n",
    "    # replace NaN with 0\n",
    "    df[col].fillna(0, inplace=True)\n",
    "    df.rename(columns={col: col}, inplace=True)\n",
    "\n",
    "df_norm = df.copy()\n",
    "for col in df.columns[1:]:\n",
    "    df_norm[col] = min_max_normalize(df[col])\n",
    "\n",
    "# plot normalized data versus year\n",
    "sns.color_palette()\n",
    "for col in df.columns[1:]:\n",
    "    plt.plot(df[\"year\"], df_norm[col], label=col, linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figures, we observe a sudden jump of the index hhi in 2019, which is due to acuisition of 21st Century Fox by Disney in Mar 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Hypothesis\n",
    "We build the hyperthesis as follows:\n",
    "- $S$ is negatively correlated with $I$, since the more people spend on subscription streaming, the less likely they are to watch movies in the cinema.\n",
    "- $M$ is positively correlated with $HHI$, since the more mergers and acquisitions in the film industry, the higher the index HHI.\n",
    "- With relatively high correlation coefficients, we can build a regression model to predict the index HHI.\n",
    "\n",
    "And we want to explore the correlation between the quantities.\n",
    "\n",
    "To construct the correlation of quantaty $A$ and $B$, we use the Pearson correlation coefficient, which is defined as,\n",
    "$$r = \\frac{\\sum_{i=1}^n (A_i - \\bar{A})(B_i - \\bar{B})}{\\sqrt{\\sum_{i=1}^n (A_i - \\bar{A})^2 \\sum_{i=1}^n (B_i - \\bar{B})^2}}$$\n",
    "where $\\bar{A}$ and $\\bar{B}$ are the mean of $A$ and $B$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation matrix of the data, excluding the year column\n",
    "corr_mat = df_norm.iloc[:, 1:].corr(method=\"pearson\")\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(corr_mat, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corration verifies our hypothesis. $S$ is negatively correlated with $I$, and $M$ is positively correlated with $HHI$. \n",
    "\n",
    "We expect M would have higher correlation with HHI but the original data has many missing quantaties of the merger and acuisition. Another thing we notice is that S is also potively correlated with HHI, which is not expected. Other quantaties have relatively low correlation with HHI.\n",
    "\n",
    " We then use the features with higher correlation coefficients to build the regression model. We choose the top 3 correlated features to build the regression model, either positively or negatively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Regression analysis\n",
    "a. We then use a linear regression model to predict the index HHI based on the other quantities. The linear regression model is defined as,\n",
    "$$y = \\beta_0 + \\beta_1 X$$\n",
    "where $y$ is the prediction, which is $HHI$ is this case. $\\beta_i$ are the coefficients to be determined in the linear model.\n",
    "\n",
    "b. We also use a simple neural network which acts as a non-linear model to predict the index HHI. The neural network is a 2-layer multi-layer perceptron (MLP), which is defined as,\n",
    "$$y = \\sigma(W_2 \\sigma(W_1 X + b_1) + b_2)$$\n",
    "where $W_1$ and $W_2$ are the weights of the first and second layer, $b_1$ and $b_2$ are the biases of the first and second layer, and $\\sigma$ is the activation function. We use the ReLU activation function for the hidden layer and the linear activation function for the output layer.\n",
    "\n",
    "We use pytorch to implement the neural network model, and use MSE loss as the loss function. We use the Adam optimizer to optimize the model parameters.\n",
    "\n",
    "c. We perform the regression analysis with quanty with higher correction to index HHI. We use the following evaluation metrics:\n",
    "\n",
    "- Mean-squared error (MSE), which is defined as:\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$$\n",
    "- R2 score\n",
    "$$R2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$$\n",
    "where $\\hat{y}_i$ is the predicted value of $y_i$, and $\\bar{y}$ is the mean of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_X_train_test_split(X, train_test_split):\n",
    "    X_train = X[:int(train_test_split*n_rows)]\n",
    "    X_test = X[int(train_test_split*n_rows):]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# perform linear regression analysis using the data with high correlation with HHI\n",
    "# get the top 3 features and their names\n",
    "top3_corr_HHI = corr_mat[\"HHI\"].sort_values(ascending=False, key=abs)[1:4]\n",
    "top2_corr_HHI = corr_mat[\"HHI\"].sort_values(ascending=False, key=abs)[1:3]\n",
    "top1_corr_HHI = corr_mat[\"HHI\"].sort_values(ascending=False, key=abs)[1:2]\n",
    "print(\"feartures with high correlation with HHI: \", top3_corr_HHI.index)\n",
    "\n",
    "train_test_split = 0.9\n",
    "testing_years = df[\"year\"][int(train_test_split*n_rows):]\n",
    "Y = df[\"HHI\"].values\n",
    "Y_train = Y[:int(train_test_split*n_rows)]\n",
    "Y_test = Y[int(train_test_split*n_rows):]\n",
    "\n",
    "# get the data for the top 3 features\n",
    "X3 = df[top3_corr_HHI.index].values\n",
    "\n",
    "# use linear regression to fit data with top 3 features\n",
    "X3_train, X3_test = generate_X_train_test_split(X3, train_test_split)\n",
    "reg3 = LinearRegression().fit(X3_train, Y_train)\n",
    "Y_pred_3 = reg3.predict(X3_test)\n",
    "mse_3 = mean_squared_error(Y_test, Y_pred_3)\n",
    "r2_3 = r2_score(Y_test, Y_pred_3)\n",
    "\n",
    "# use 2 feature to fit the data\n",
    "X2 = df[top2_corr_HHI.index].values\n",
    "X2_train, X2_test = generate_X_train_test_split(X2, train_test_split)\n",
    "reg2 = LinearRegression().fit(X2_train, Y_train)\n",
    "Y_pred_2 = reg2.predict(X2_test)\n",
    "mse_2 = mean_squared_error(Y_test, Y_pred_2)\n",
    "r2_2 = r2_score(Y_test, Y_pred_2)\n",
    "\n",
    "# use only 1 feature to fit the data\n",
    "X1 = df[top1_corr_HHI.index].values\n",
    "X1_train, X1_test = generate_X_train_test_split(X1, train_test_split)\n",
    "reg1 = LinearRegression().fit(X1_train, Y_train)\n",
    "Y_pred_1 = reg1.predict(X1_test)\n",
    "mse_1 = mean_squared_error(Y_test, Y_pred_1)\n",
    "r2_1 = r2_score(Y_test, Y_pred_1)\n",
    "\n",
    "# sumrize the results\n",
    "print(\"Mean Squared Error for 3 features: \", mse_3)\n",
    "print(\"Mean Squared Error for 2 features: \", mse_2)\n",
    "print(\"Mean Squared Error for 1 features: \", mse_1)\n",
    "print(\"R2 score for 3 features: \", r2_3)\n",
    "print(\"R2 score for 2 features: \", r2_2)\n",
    "print(\"R2 score for 1 features: \", r2_1)\n",
    "\n",
    "# plot preded MSE and R2 score versus number of features\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([3, 2, 1], min_max_normalize(np.array([mse_3, mse_2, mse_1])), label=\"Mean Squared Error\", linewidth=3)\n",
    "plt.plot([3, 2, 1], [r2_3, r2_2, r2_1], label=\"R2 Score\", linewidth=3)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot the predicted values versus and ground truth values versus year as scatter plots\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(testing_years, Y_test, color=\"red\", s=100, label=\"Ground truth\")\n",
    "plt.scatter(testing_years, Y_pred_3,  color=\"blue\", s=100, label=\"Predicted with 3 features\")\n",
    "plt.scatter(testing_years, Y_pred_2,  color=\"orange\", s=100, label=\"Predicted with 2 features\")\n",
    "plt.scatter(testing_years, Y_pred_1,  color=\"black\", s=100, label=\"Predicted with 1 feature\")\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Testing Year\")\n",
    "plt.ylabel(\"HHI\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that by using more features, the linear model can predict HHI with higher R2 score and lower MSE. Thus we should should choose more feature to perform the regression analysis. And we will use 3 features in the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# create a simple two-layer neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "neural_net = NeuralNet(input_size=3, hidden_size=8, num_classes=1)\n",
    "\n",
    "# prepare the data for the neural network\n",
    "X = df[top3_corr_HHI.index].values\n",
    "Y = df[\"HHI\"].values\n",
    "Y_train = Y[:int(train_test_split*n_rows)]\n",
    "Y_test = Y[int(train_test_split*n_rows):]\n",
    "X_train, X_test = generate_X_train_test_split(X, train_test_split)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).view(-1, 1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# loss and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(neural_net.parameters(), lr=0.001)\n",
    "\n",
    "# train the model\n",
    "for epoch in range(100):\n",
    "    for i in range(len(X_train)):\n",
    "        x, y = X_train[i], Y_train[i]\n",
    "        y_pred = neural_net(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print(f\"Epoch {epoch}, loss: {loss.item()}\")\n",
    "\n",
    "# test the model\n",
    "losses = []\n",
    "Y_preds = []\n",
    "for i in range(len(X_test)):\n",
    "    x, y = X_test[i], Y_test[i]\n",
    "    with torch.no_grad():\n",
    "        y_pred = neural_net(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    losses.append(loss.item())\n",
    "    Y_preds.append(y_pred.item())\n",
    "    print(f\"Test step {i}, loss: {loss.item()}\")\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_preds)\n",
    "r2 = r2_score(Y_test, Y_preds)\n",
    "print(\"Mean Squared Error with NN: \", mse)\n",
    "print(\"R2 score with NN: \", r2)\n",
    "\n",
    "# plot the predicted values versus and ground truth values versus year as scatter plots\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(testing_years, Y_test, color=\"red\", s=100, label=\"Ground truth\")\n",
    "plt.scatter(testing_years, Y_preds,  color=\"blue\", s=100, label=\"Predicted with NN\")\n",
    "plt.scatter(testing_years, Y_pred_3,  color=\"orange\", s=100, label=\"Predicted by Linear Regression\")\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Testing Year\")\n",
    "plt.ylabel(\"HHI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform linear regression analysis with the data with high correlation\n",
    "# # print columns with high correlation larger than a threshold\n",
    "# corr_threshold = 0.8\n",
    "# high_corr_cols = []\n",
    "# for col in corr_mat.columns:\n",
    "#     for row in corr_mat.index:\n",
    "#         if row != col and corr_mat.loc[row, col] > corr_threshold:\n",
    "#             high_corr_cols.append((row, col))\n",
    "# print(\"Columns with high correlation > corr_threshold: \", high_corr_cols)\n",
    "\n",
    "# # perform linear regression analysis with the data with high correlation\n",
    "# for col1, col2 in high_corr_cols:\n",
    "#     X = df[col1].values.reshape(-1, 1)\n",
    "#     y = df[col2].values.reshape(-1, 1)\n",
    "#     reg = LinearRegression().fit(X, y)\n",
    "#     y_pred = reg.predict(X)\n",
    "#     mse = mean_squared_error(y, y_pred)\n",
    "#     print(f\"Linear regression analysis for {col1} and {col2}\")\n",
    "#     print(f\"Mean squared error: {mse}\")\n",
    "#     print(f\"R^2 score: {reg.score(X, y)}\")\n",
    "\n",
    "#     plt.scatter(X, y, label=\"Actual data\")\n",
    "#     plt.plot(X, y_pred, color='red', label=\"Linear regression fit\")\n",
    "#     plt.xlabel(col1)\n",
    "#     plt.ylabel(col2)\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Conclusions\n",
    "\n",
    "In this experiment, we perform correlation analysis and regression analysis to investigate the relationship between the index HHI and other quantities. We observe that the index HHI is negatively correlated with $I$, and positively correlated with $S$ and $M$. Other quantities have relatively low correlation with the index HHI.\n",
    "\n",
    "We build a linear regression model and a neural network model to predict the index HHI based on the quantities with higher correlation absolute values. We observe that the linear model can predict the index HHI with higher R2 score and lower MSE by using more features. We find that in this case, the linear model outperforms neural network due to the relatively small size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deWaard, A. (2023). Derivative Media: How Wall Street Devours Culture. Draft.\n",
    "\n",
    "Bagdikian, B. H. (2004). The new media monopoly. Beacon Press.\n",
    "\n",
    "Baker, C. E., & McDonald, T. (2018). Media concentration and democracy: Why ownership matters. Cambridge University Press.\n",
    "\n",
    "Cunningham, S., & Craig, D. (2018). Social media, convergence, and the role of the user in media and information policy. Media International Australia, 168(1), 59-72.\n",
    "\n",
    "Cunningham, S., & Sinclair, J. (2017). Beyond the horizon: The future of global media ownership research. Media International Australia, 163(1), 68-81.\n",
    "\n",
    "Doyle, G., & McChesney, R. W. (2020). Dollarocracy: How the money and media election complex is destroying America. The New Press.\n",
    "\n",
    "McChesney, R. W. (1999). Rich media, poor democracy: Communication politics in dubious times. University of Illinois Press.\n",
    "\n",
    "Napoli, P. M. (2001). Deconstructing the diversity principle. Communication Law and Policy, 6(3), 355-388.\n",
    "\n",
    "Picard, R. G. (2012). Media firms: Structures, operations, and performance. Routledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data appendix for HHI Dashboard\n",
    "\n",
    "[Film distributor market share in U.S. 1995 to 2019](https://docs.google.com/spreadsheets/d/1a8hoi2FErrxq6tz1-r6ZBf6H2sB86CVRtcd1nBohzso/edit#gid=754955376)\n",
    "\n",
    "\n",
    "[Recorded music market share dataset](https://docs.google.com/spreadsheets/d/1b8enjNSr0trcJgAQXUqNDWeo5Orgi2IUJkfFxHNZZR4/edit#gid=586095138)\n",
    "\n",
    "[Share of music streaming subscribers worldwide in 2023 Q3](https://www.statista.com/statistics/653926/music-streaming-service-subscriber-share/)\n",
    "\n",
    "[Comic publisher: store market share in the U.S. 2023](https://www.counterpointresearch.com/insights/global-xr-ar-vr-headsets-market-share/)\n",
    "\n",
    "[VR market share source : counterpoint](https://www.counterpointresearch.com/insights/global-xr-ar-vr-headsets-market-share/)\n",
    "\n",
    "[iOS gaming publishers market share U.S. 2021 Q2](https://www.statista.com/statistics/298718/sessions-spent-android-mobile-games-publisher-usa/)\n",
    "\n",
    "[Revenue share of RPG gaming apps U.S. 2021 Q1](https://www.statista.com/statistics/1249221/market-share-us-top-rpg-game-apps-revenue/)\n",
    "\n",
    "[Market share of leading commercial printing companies U.S. 2016](https://www.statista.com/statistics/1391622/big-3-video-game-market-share-worldwide/)\n",
    "\n",
    "[Nintendo, Microsoft and Sony(Big 3) video games market share worldwide in 2022](https://www.statista.com/statistics/1391622/big-3-video-game-market-share-worldwide/)\n",
    "\n",
    "[Market share of rental cameras U.S. from 2020 to 2023 by brand](https://www.statista.com/statistics/1222727/market-share-camera-rental-us-by-brand/)\n",
    "\n",
    "[Market share of leading film studios in the U.S. and Canada from 2010 to 2023](https://www.statista.com/statistics/187171/market-share-of-film-studios-in-north-america-2010/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
